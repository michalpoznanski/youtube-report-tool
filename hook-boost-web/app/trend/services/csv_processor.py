"""
Serwis do przetwarzania danych z raport√≥w CSV dla modu≈Çu trend.
Zapewnia niezawodne wczytywanie i analizƒô danych z plik√≥w CSV.
"""

import pandas as pd
import logging
from datetime import date, timedelta
from typing import List, Dict, Any, Optional
from pathlib import Path

logger = logging.getLogger(__name__)

class CSVProcessor:
    """Klasa do przetwarzania plik√≥w CSV z raportami trend√≥w"""
    
    def __init__(self):
        # U≈ºyj tej samej ≈õcie≈ºki co API routes
        self.base_path = Path("/mnt/volume/reports")
    
    def get_trend_data(self, category: str, report_date: date) -> List[Dict[str, Any]]:
        """
        Pobiera dane trend√≥w dla danej kategorii i daty.
        U≈ºywa tej samej logiki co API routes.
        """
        try:
            print(f"üöÄ CSV Processor: Start dla kategorii {category}, data {report_date}")
            
            # U≈ºyj tej samej logiki co API routes
            import os
            reports_dir = "/mnt/volume/reports"
            
            if not os.path.exists(reports_dir):
                print(f"‚ùå CSV Processor: Katalog {reports_dir} nie istnieje!")
                return []
            
            # Znajd≈∫ pliki CSV dla kategorii
            csv_files = []
            for file in os.listdir(reports_dir):
                if file.startswith(f"report_{category.upper()}_") and file.endswith('.csv'):
                    csv_files.append(file)
            
            print(f"üìÅ CSV Processor: Znalezione pliki: {csv_files}")
            
            if not csv_files:
                print(f"‚ùå CSV Processor: Brak plik√≥w CSV dla kategorii {category}")
                return []
            
            # U≈ºyj najnowszego pliku
            latest_file = sorted(csv_files)[-1]  # Ostatni alfabetycznie = najnowszy
            file_path = os.path.join(reports_dir, latest_file)
            
            print(f"üìÅ CSV Processor: U≈ºywam pliku: {latest_file}")
            
            # Wczytaj CSV u≈ºywajƒÖc pandas
            import pandas as pd
            df = pd.read_csv(file_path)
            
            print(f"‚úÖ CSV Processor: Wczytano {len(df)} wierszy z {latest_file}")
            
            # Konwertuj do listy s≈Çownik√≥w
            result_list = []
            for _, row in df.iterrows():
                result_list.append({
                    'title': str(row.get('Title', '')),
                    'views': int(row.get('View_Count', 0)),
                    'delta': 0,  # Na razie bez delta
                    'video_type': str(row.get('video_type', 'Longform')),
                    'thumbnail_url': f"https://img.youtube.com/vi/{row.get('Video_ID', '')}/mqdefault.jpg",
                    'video_id': str(row.get('Video_ID', '')),
                    'channel': str(row.get('Channel_Name', '')),
                    'duration': str(row.get('Duration', '')),
                    'description': str(row.get('Description', '')),
                    'tags': str(row.get('Tags', '')),
                    'like_count': int(row.get('Like_Count', 0)),
                    'topic_categories': str(row.get('Topic_Categories', '')),
                    'channel_id': str(row.get('Channel_ID', '')),
                    'date_published': str(row.get('Date_of_Publishing', '')),
                    'hour_published': str(row.get('Hour_GMT2', ''))
                })
            
            print(f"‚úÖ CSV Processor: Zwracam {len(result_list)} wideo")
            return result_list
            
        except Exception as e:
            print(f"‚ùå CSV Processor: B≈ÇƒÖd: {e}")
            return []
    
    def _load_csv_safely(self, file_path: Path) -> Optional[pd.DataFrame]:
        """
        Bezpiecznie wczytuje plik CSV z obs≈ÇugƒÖ b≈Çƒôd√≥w.
        
        Args:
            file_path (Path): ≈öcie≈ºka do pliku CSV
            
        Returns:
            Optional[pd.DataFrame]: DataFrame z danymi lub None w przypadku b≈Çƒôdu
        """
        try:
            print(f"üîç CSV Processor: Pr√≥ba wczytania pliku: {file_path}")
            print(f"üîç CSV Processor: Plik istnieje: {file_path.exists()}")
            
            if not file_path.exists():
                print(f"‚ùå CSV Processor: Plik nie istnieje: {file_path}")
                logger.debug(f"Plik nie istnieje: {file_path}")
                return None
            
            # Sprawd≈∫ rozmiar pliku
            file_size = file_path.stat().st_size
            print(f"üîç CSV Processor: Rozmiar pliku: {file_size} bajt√≥w")
            
            if file_size == 0:
                print(f"‚ùå CSV Processor: Plik jest pusty: {file_path}")
                logger.warning(f"Plik CSV jest pusty: {file_path}")
                return None
            
            # Wczytaj CSV z obs≈ÇugƒÖ r√≥≈ºnych kodowa≈Ñ
            print(f"üîç CSV Processor: Wczytujƒô CSV...")
            df = pd.read_csv(file_path, encoding='utf-8')
            print(f"‚úÖ CSV Processor: Pomy≈õlnie wczytano CSV: {len(df)} wierszy, {len(df.columns)} kolumn")
            
            # Sprawd≈∫ czy DataFrame nie jest pusty
            if df.empty:
                print(f"‚ùå CSV Processor: DataFrame jest pusty: {file_path}")
                logger.warning(f"Plik CSV jest pusty: {file_path}")
                return None
            
            # Sprawd≈∫ pierwsze kilka wierszy
            print(f"üîç CSV Processor: Pierwsze 3 wiersze:")
            print(df.head(3))
            
            return df
            
        except Exception as e:
            print(f"‚ùå CSV Processor: B≈ÇƒÖd podczas wczytywania {file_path}: {e}")
            logger.error(f"B≈ÇƒÖd podczas wczytywania CSV {file_path}: {e}")
            return None
    
    def _process_trend_data(self, today_df: pd.DataFrame, yesterday_df: Optional[pd.DataFrame]) -> List[Dict[str, Any]]:
        """
        Przetwarza dane trend√≥w i oblicza przyrosty.
        
        Args:
            today_df (pd.DataFrame): Dzisiejsze dane
            yesterday_df (Optional[pd.DataFrame]): Wczorajsze dane
            
        Returns:
            List[Dict[str, Any]]: Lista przetworzonych rekord√≥w
        """
        try:
            # Skopiuj dzisiejsze dane
            result_df = today_df.copy()
            
            # Dodaj kolumnƒô video_type na podstawie Duration
            result_df['video_type'] = result_df['Duration'].apply(
                lambda x: "Shorts" if pd.notna(x) and str(x).startswith('PT') and 'S' in str(x) and int(str(x).split('S')[0].split('T')[-1]) <= 180 else "Longform"
            )
            
            # Inicjalizuj kolumnƒô delta
            result_df['delta'] = 0
            
            # Je≈õli mamy wczorajsze dane, oblicz przyrosty
            if yesterday_df is not None and not yesterday_df.empty:
                # Mapuj wczorajsze wy≈õwietlenia po video_id
                yesterday_views = yesterday_df.set_index('Video_ID')['View_Count'].to_dict()
                
                # Oblicz delta
                result_df['delta'] = result_df.apply(
                    lambda row: row['View_Count'] - yesterday_views.get(row['Video_ID'], 0), 
                    axis=1
                )
            
            # Dodaj kolumnƒô thumbnail_url (YouTube thumbnail)
            result_df['thumbnail_url'] = result_df['Video_ID'].apply(
                lambda x: f"https://img.youtube.com/vi/{x}/mqdefault.jpg" if pd.notna(x) else ""
            )
            
            # Sortuj malejƒÖco wed≈Çug delta
            result_df = result_df.sort_values('delta', ascending=False)
            
            # Zwr√≥ƒá wszystkie wyniki (nie tylko top 50)
            top_results = result_df
            
            # Konwertuj do listy s≈Çownik√≥w
            result_list = []
            for _, row in top_results.iterrows():
                result_list.append({
                    'title': str(row.get('Title', '')),
                    'views': int(row.get('View_Count', 0)),
                    'delta': int(row.get('delta', 0)),
                    'video_type': str(row.get('video_type', 'Longform')),
                    'thumbnail_url': str(row.get('thumbnail_url', '')),
                    'video_id': str(row.get('Video_ID', '')),
                    'channel': str(row.get('Channel_Name', '')),
                    'duration': str(row.get('Duration', '')),
                    'description': str(row.get('Description', '')),
                    'tags': str(row.get('Tags', '')),
                    'like_count': int(row.get('Like_Count', 0)),
                    'topic_categories': str(row.get('Topic_Categories', '')),
                    'channel_id': str(row.get('Channel_ID', '')),
                    'date_published': str(row.get('Date_of_Publishing', '')),
                    'hour_published': str(row.get('Hour_GMT2', ''))
                })
            
            return result_list
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas przetwarzania danych trend√≥w: {e}")
            return []
    
    def get_available_dates(self, category: str) -> List[str]:
        """
        Zwraca listƒô dostƒôpnych dat dla danej kategorii.
        
        Args:
            category (str): Nazwa kategorii
            
        Returns:
            List[str]: Lista dat w formacie YYYY-MM-DD
        """
        try:
            if not self.base_path.exists():
                logger.warning(f"Katalog raport√≥w nie istnieje: {self.base_path}")
                return []
            
            # Wzorzec pliku
            pattern = f"report_{category.upper()}_*.csv"
            
            # Znajd≈∫ pliki
            csv_files = list(self.base_path.glob(pattern))
            
            # WyciƒÖgnij daty z nazw plik√≥w
            dates = []
            for file_path in csv_files:
                try:
                    # Format: report_PODCAST_2025-08-13.csv
                    filename = file_path.stem  # bez rozszerzenia
                    date_part = filename.split('_')[-1]
                    
                    # Sprawd≈∫ czy to poprawna data
                    date.fromisoformat(date_part)
                    dates.append(date_part)
                except (ValueError, IndexError):
                    continue
            
            # Sortuj daty malejƒÖco (najnowsze pierwsze)
            dates.sort(reverse=True)
            
            logger.info(f"Znaleziono {len(dates)} dostƒôpnych dat dla kategorii {category}")
            return dates
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas pobierania dostƒôpnych dat dla {category}: {e}")
            return []


# Funkcja pomocnicza dla ≈Çatwiejszego dostƒôpu
def get_trend_data(category: str, report_date: date) -> List[Dict[str, Any]]:
    """
    Funkcja pomocnicza do pobierania danych trend√≥w.
    
    Args:
        category (str): Nazwa kategorii
        report_date (date): Data raportu
        
    Returns:
        List[Dict[str, Any]]: Lista danych trend√≥w
    """
    processor = CSVProcessor()
    return processor.get_trend_data(category, report_date)
