#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ•·ï¸ SCRAPER TEST - Test scrapowania Channel ID z YouTube
======================================================

Test kodu uÅ¼ytkownika do wyciÄ…gania Channel ID bez API
"""

import requests
import re
import time

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def extract_channel_id(url):
    try:
        print(f"ğŸ” Sprawdzam: {url}")
        response = requests.get(url, headers=HEADERS, timeout=10)
        html = response.text

        # Szukaj ID kanaÅ‚u (YouTube handle: @nazwa)
        handle_match = re.search(r'"channelId":"(UC[\w-]{22})"', html)
        if handle_match:
            channel_id = handle_match.group(1)
            print(f"   âœ… Znaleziono przez handle: {channel_id}")
            return channel_id

        # Szukaj ID z klasycznych kanaÅ‚Ã³w
        match = re.search(r"youtube\.com/channel/(UC[\w-]{22})", url)
        if match:
            channel_id = match.group(1)
            print(f"   âœ… Znaleziono przez URL: {channel_id}")
            return match.group(1)
        
        # Dodatkowe wzorce
        additional_patterns = [
            r'"browseEndpoint":{"browseId":"(UC[\w-]{22})"',
            r'"channelMetadataRenderer":{"title":"[^"]+","description":"[^"]*","rssUrl":"[^"]*","channelUrl":"[^"]*","ownerUrls":\["[^"]*"\],"avatar"[^}]+},"channelId":"(UC[\w-]{22})"',
            r'<meta property="og:url" content="https://www\.youtube\.com/channel/(UC[\w-]{22})"'
        ]
        
        for pattern in additional_patterns:
            match = re.search(pattern, html)
            if match:
                channel_id = match.group(1)
                print(f"   âœ… Znaleziono przez wzorzec dodatkowy: {channel_id}")
                return channel_id

        print(f"   âŒ Nie znaleziono Channel ID")
        return None

    except Exception as e:
        print(f"   ğŸ’¥ BÅ‚Ä…d przy {url}: {e}")

    return None


def get_channel_ids_from_links(links):
    ids = {}
    for i, link in enumerate(links):
        print(f"\nğŸ“‹ Test {i+1}/{len(links)}")
        
        # Pauza miÄ™dzy requestami Å¼eby nie przeciÄ…Å¼aÄ‡ YouTube
        if i > 0:
            time.sleep(1)
            
        cid = extract_channel_id(link.strip())
        if cid:
            ids[link] = cid
        
    return ids


if __name__ == "__main__":
    print("ğŸ•·ï¸ TEST SCRAPOWANIA CHANNEL ID")
    print("=" * 50)
    
    sample_links = [
        "https://www.youtube.com/@pudelektv",
        "https://www.youtube.com/@radiozet", 
        "https://www.youtube.com/watch?v=dQw4w9WgXcQ"  # link do filmu
    ]

    print(f"ğŸ¯ TestujÄ™ {len(sample_links)} linkÃ³w...")
    
    start_time = time.time()
    results = get_channel_ids_from_links(sample_links)
    end_time = time.time()

    print(f"\nğŸ“Š WYNIKI:")
    print("=" * 30)
    
    for link, cid in results.items():
        print(f"âœ… {link}")
        print(f"   â†’ {cid}")
    
    failed = len(sample_links) - len(results)
    if failed > 0:
        print(f"\nâŒ Nie udaÅ‚o siÄ™: {failed} linkÃ³w")
    
    print(f"\nâ±ï¸ Czas wykonania: {end_time - start_time:.1f}s")
    print(f"ğŸ’° Koszt quota API: 0 (scraping)")
    print(f"ğŸŒ IloÅ›Ä‡ requestÃ³w HTTP: {len(sample_links)}") 