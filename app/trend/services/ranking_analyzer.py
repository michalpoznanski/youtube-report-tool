import json
import pandas as pd
from datetime import date, timedelta
import datetime
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class RankingAnalyzer:
    def __init__(self, base_path_str: str = None):
        from app.config.settings import settings
        self.base_path = Path(base_path_str) if base_path_str else settings.reports_path
        self.base_path.mkdir(exist_ok=True)
        print(f"‚úÖ RankingAnalyzer zainicjalizowany z ≈õcie≈ºkƒÖ: {self.base_path}")

    def run_analysis_for_category(self, category: str) -> bool:
        """
        Implementuje prawdziwƒÖ logikƒô analizy rankingowej:
        1. Wczytuje KILKA najnowszych raport√≥w CSV (ostatnie 3-5 dni)
        2. ≈ÅƒÖczy wszystkie dane w jednƒÖ bazƒô
        3. Tworzy Top 10 z po≈ÇƒÖczonych danych
        4. Zapisuje stan na jutro
        """
        try:
            today = date.today()
            print(f"üîÑ Rozpoczynam analizƒô rankingu dla kategorii: {category}")
            
            # 1. WCZYTAJ KILKA NAJNOWSZYCH RAPORT√ìW CSV (ostatnie 5 dni)
            pattern = f"report_{category.upper()}_*.csv"
            csv_files = list(self.base_path.glob(pattern))
            
            if not csv_files:
                print(f"‚ö†Ô∏è Nie znaleziono ≈ºadnych raport√≥w CSV dla {category}. Pomijam analizƒô.")
                logger.warning(f"Nie znaleziono raport√≥w CSV dla {category}")
                return False
            
            # Sortuj pliki po dacie (najnowsze na ko≈Ñcu)
            csv_files_sorted = sorted(csv_files, key=lambda x: x.stem.split('_')[-1])
            
            # We≈∫ ostatnie 5 raport√≥w (lub wszystkie je≈õli mniej ni≈º 5)
            recent_csv_files = csv_files_sorted[-5:] if len(csv_files_sorted) >= 5 else csv_files_sorted
            
            print(f"üìä Znaleziono {len(csv_files)} raport√≥w CSV dla {category}")
            print(f"üìä U≈ºywam {len(recent_csv_files)} najnowszych raport√≥w:")
            for csv_file in recent_csv_files:
                date_str = csv_file.stem.split('_')[-1]
                print(f"   - {csv_file.name} (data: {date_str})")
            
            # 2. WCZYTAJ I PO≈ÅƒÑCZ WSZYSTKIE DANE Z CSV
            print("üîÑ Wczytujƒô i ≈ÇƒÖczƒô dane z wszystkich raport√≥w CSV...")
            
            all_videos = {}  # S≈Çownik: video_id -> najnowsze dane
            
            for csv_file in recent_csv_files:
                date_str = csv_file.stem.split('_')[-1]
                print(f"üìä Wczytujƒô raport: {csv_file.name}")
                
                try:
                    df = pd.read_csv(csv_file)
                    print(f"   ‚úÖ Wczytano {len(df)} film√≥w z {date_str}")
                    
                    # Przetw√≥rz ka≈ºdy film z tego raportu
                    for _, row in df.iterrows():
                        video_id = str(row.get('Video_ID', ''))
                        if not video_id:
                            continue
                        
                        video_data = {
                            'video_id': video_id,
                            'title': str(row.get('Title', '')),
                            'channel': str(row.get('Channel_Name', '')),
                            'views': int(row.get('View_Count', 0)),
                            'thumbnail_url': str(row.get('Thumbnail_URL', '')),
                            'published_date': str(row.get('Date_of_Publishing', '')),
                            'video_type': str(row.get('Video_Type', 'longform')),
                            'source_date': date_str,
                            'report_file': csv_file.name
                        }
                        
                        # Je≈õli film ju≈º istnieje, zaktualizuj danymi z nowszego raportu
                        if video_id in all_videos:
                            existing_video = all_videos[video_id]
                            existing_date = datetime.datetime.strptime(existing_video['source_date'], '%Y-%m-%d').date()
                            new_date = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()
                            
                            if new_date > existing_date:
                                # Nowszy raport - aktualizuj dane
                                old_views = existing_video['views']
                                all_videos[video_id] = video_data
                                print(f"   üîÑ Zaktualizowano film: {video_data['title'][:50]}... (wy≈õwietlenia: {old_views} ‚Üí {video_data['views']})")
                            # Je≈õli starszy raport - pomi≈Ñ
                        else:
                            # Nowy film - dodaj
                            all_videos[video_id] = video_data
                            print(f"   üÜï Dodano nowy film: {video_data['title'][:50]}...")
                
                except Exception as e:
                    print(f"   ‚ùå B≈ÇƒÖd podczas wczytywania {csv_file.name}: {e}")
                    continue
            
            print(f"‚úÖ Po≈ÇƒÖczono dane z {len(recent_csv_files)} raport√≥w: {len(all_videos)} unikalnych film√≥w")
            
            # Sprawd≈∫ czy Marcin Banot jest w danych
            marcin_banot_found = False
            for video in all_videos.values():
                if 'Marcin Banot' in video['title'] or 'Cyprian Majcher' in video['channel']:
                    print(f"üéØ ZNALEZIONO: {video['title']} - {video['channel']} - {video['views']} wy≈õwietle≈Ñ z {video['source_date']}")
                    marcin_banot_found = True
            
            if not marcin_banot_found:
                print(f"‚ö†Ô∏è NIE ZNALEZIONO filmu Marcin Banot w danych!")
            else:
                print(f"‚úÖ ZNALEZIONO film Marcin Banot w danych!")
            
            # 3. PODZIEL NA SHORTS I LONG-FORM
            print("üîÑ Dzielƒô filmy na kategorie...")
            
            shorts_videos = []
            longform_videos = []
            
            for video in all_videos.values():
                if video['video_type'].lower() == 'shorts':
                    shorts_videos.append(video)
                else:
                    longform_videos.append(video)
            
            print(f"üì± Shorts: {len(shorts_videos)} film√≥w")
            print(f"üé¨ Long-form: {len(longform_videos)} film√≥w")
            
            # 4. POSORTUJ I WYBIERZ TOP 10 (OPCJA A - po wy≈õwietleniach)
            print("üèÜ Sortujƒô i wybieram Top 10...")
            
            # Sortuj po wy≈õwietleniach (malejƒÖco)
            shorts_sorted = sorted(shorts_videos, key=lambda x: x['views'], reverse=True)
            longform_sorted = sorted(longform_videos, key=lambda x: x['views'], reverse=True)
            
            # Wybierz Top 10
            top_10_shorts = shorts_sorted[:10]
            top_10_longform = longform_sorted[:10]
            
            print(f"üèÜ Top 10 Shorts: {len(top_10_shorts)} film√≥w")
            print(f"üèÜ Top 10 Long-form: {len(top_10_longform)} film√≥w")
            
            # 5. KONWERTUJ DO FORMATU STAREGO SYSTEMU (z trendami)
            print("üîÑ Konwertujƒô dane do formatu starego systemu...")
            
            def convert_to_old_format(videos_list, video_type):
                """Konwertuje dane do formatu starego systemu z trendami"""
                converted = []
                for i, video in enumerate(videos_list):
                    # Oblicz trend na podstawie pozycji
                    if i == 0:
                        trend = 'new'  # Pierwszy = nowy
                    elif i < 3:
                        trend = 'up'   # Top 3 = w g√≥rƒô
                    else:
                        trend = 'stable'  # Reszta = stabilne
                    
                    converted_video = {
                        'video_id': video.get('video_id', ''),
                        'title': video.get('title', ''),
                        'channel': video.get('channel', ''),
                        'views': video.get('views', 0),
                        'trend': trend,
                        'thumbnail_url': video.get('thumbnail_url', ''),
                        'published_date': video.get('published_date', ''),
                        'video_type': video_type,
                        'source_date': video.get('source_date', ''),
                        'report_file': video.get('report_file', '')
                    }
                    converted.append(converted_video)
                return converted
            
            # Konwertuj rankingi
            shorts_formatted = convert_to_old_format(top_10_shorts, 'shorts')
            longform_formatted = convert_to_old_format(top_10_longform, 'longform')
            
            # Przygotuj historiƒô pozycji (dla kompatybilno≈õci)
            history = {}
            for video in shorts_formatted + longform_formatted:
                history[video['video_id']] = {
                    'current_position': shorts_formatted.index(video) + 1 if video in shorts_formatted else longform_formatted.index(video) + 1,
                    'previous_position': None,  # Bƒôdzie dostƒôpne w nastƒôpnej analizie
                    'trend': video['trend'],
                    'source_date': video.get('source_date', ''),
                    'report_file': video.get('report_file', '')
                }
            
            # 6. ZAPISZ STAN NA JUTRO (plik-pamiƒôƒá)
            print("üíæ Zapisujƒô ranking na jutro...")
            
            # Znajd≈∫ najnowszƒÖ datƒô z u≈ºytych raport√≥w
            latest_report_date = max([video['source_date'] for video in all_videos.values()])
            
            final_ranking = {
                'shorts': shorts_formatted,
                'longform': longform_formatted,
                'history': history,
                'last_updated': today.isoformat(),
                'analysis_date': today.isoformat(),
                'latest_csv_date': latest_report_date,
                'csv_files_used': [f.name for f in recent_csv_files],
                'total_videos_analyzed': len(all_videos),
                'shorts_count': len(shorts_videos),
                'longform_count': len(longform_videos),
                'csv_reports_count': len(recent_csv_files),
                'analysis_method': 'multiple_csv_analysis',
                'date_range': f"{min([video['source_date'] for video in all_videos.values()])} - {latest_report_date}"
            }
            
            output_path = self.base_path / f"ranking_{category.upper()}_{today}.json"
            print(f"üìÅ Zapisujƒô ranking do: {output_path}")
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(final_ranking, f, indent=4, ensure_ascii=False)
            
            print(f"‚úÖ Zapisano analizƒô rankingu dla {category.upper()} w pliku: {output_path}")
            print(f"üìä Statystyki:")
            print(f"   - U≈ºyte raporty CSV: {len(recent_csv_files)}")
            print(f"   - Zakres dat: {min([video['source_date'] for video in all_videos.values()])} - {latest_report_date}")
            print(f"   - Unikalne filmy: {len(all_videos)}")
            print(f"   - Top 10 Shorts: {len(top_10_shorts)} film√≥w")
            print(f"   - Top 10 Long-form: {len(top_10_longform)} film√≥w")
            print(f"   - Metoda analizy: Analiza z {len(recent_csv_files)} raport√≥w CSV")
            
            logger.info(f"Pomy≈õlnie wygenerowano ranking dla {category}: {len(top_10_shorts)} shorts, {len(top_10_longform)} longform")
            
            return True
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas analizy rankingu dla {category}: {e}")
            logger.error(f"B≈ÇƒÖd podczas analizy rankingu dla {category}: {e}")
            import traceback
            traceback.print_exc()
            return False

    def get_latest_ranking(self, category: str) -> Dict[str, Any]:
        """
        Pobiera najnowszy ranking dla danej kategorii.
        
        Args:
            category (str): Nazwa kategorii
            
        Returns:
            Dict[str, Any]: Ranking lub pusty s≈Çownik je≈õli nie istnieje
        """
        try:
            today = date.today()
            ranking_path = self.base_path / f"ranking_{category.upper()}_{today}.json"
            
            if ranking_path.exists():
                with open(ranking_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                print(f"‚ÑπÔ∏è Brak rankingu dla {category} z dzisiaj: {ranking_path}")
                return {"shorts": [], "longform": [], "error": "Brak rankingu"}
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas wczytywania rankingu dla {category}: {e}")
            logger.error(f"B≈ÇƒÖd podczas wczytywania rankingu dla {category}: {e}")
            return {"shorts": [], "longform": [], "error": str(e)}
