"""
Serwis do przetwarzania danych z raport√≥w CSV dla modu≈Çu trend.
Zapewnia niezawodne wczytywanie i analizƒô danych z plik√≥w CSV.
"""

import pandas as pd
import logging
from datetime import date, timedelta
from typing import List, Dict, Any, Optional
from pathlib import Path

logger = logging.getLogger(__name__)

class CSVProcessor:
    """Klasa do przetwarzania plik√≥w CSV z raportami trend√≥w"""
    
    def __init__(self):
        # U≈ºyj tej samej ≈õcie≈ºki co csv_generator
        from ...config.settings import settings
        self.base_path = settings.reports_path
    
    def get_trend_data(self, category: str, report_date: date) -> List[Dict[str, Any]]:
        """
        Pobiera dane trend√≥w dla danej kategorii i daty.
        
        Args:
            category (str): Nazwa kategorii (np. "PODCAST")
            report_date (date): Data raportu (ignorowana - u≈ºywa najnowszego dostƒôpnego pliku)
            
        Returns:
            List[Dict[str, Any]]: Lista top 50 wynik√≥w z danymi trend√≥w
        """
        try:
            # Znajd≈∫ najnowszy dostƒôpny plik CSV dla danej kategorii
            pattern = f"report_{category.upper()}_*.csv"
            csv_files = list(self.base_path.glob(pattern))
            
            if not csv_files:
                print(f"‚ùå CSV Processor: Nie znaleziono plik√≥w CSV dla kategorii {category}")
                logger.warning(f"Nie znaleziono plik√≥w CSV dla kategorii {category}")
                return []
            
            # We≈∫ najnowszy plik (sortuj po nazwie)
            latest_file = sorted(csv_files)[-1]
            print(f"üîç CSV Processor: U≈ºywam najnowszego pliku: {latest_file}")
            
            # Wczytaj najnowszy raport
            latest_df = self._load_csv_safely(latest_file)
            if latest_df is None or latest_df.empty:
                print(f"‚ùå CSV Processor: Nie mo≈ºna wczytaƒá raportu: {latest_file}")
                logger.warning(f"Nie mo≈ºna wczytaƒá raportu: {latest_file}")
                return []
            
            # Znajd≈∫ poprzedni plik (dla obliczenia delta)
            if len(csv_files) > 1:
                previous_file = sorted(csv_files)[-2]
                print(f"üîç CSV Processor: U≈ºywam poprzedniego pliku: {previous_file}")
                previous_df = self._load_csv_safely(previous_file)
            else:
                previous_df = None
            
            # Przygotuj dane
            result_data = self._process_trend_data(latest_df, previous_df)
            
            print(f"‚úÖ CSV Processor: Pomy≈õlnie przetworzono {len(result_data)} rekord√≥w dla kategorii {category}")
            logger.info(f"Pomy≈õlnie przetworzono {len(result_data)} rekord√≥w dla kategorii {category}")
            return result_data
            
        except Exception as e:
            print(f"‚ùå CSV Processor: B≈ÇƒÖd: {e}")
            logger.error(f"B≈ÇƒÖd podczas przetwarzania danych trend√≥w dla {category} {report_date}: {e}")
            return []
    
    def _load_csv_safely(self, file_path: Path) -> Optional[pd.DataFrame]:
        """
        Bezpiecznie wczytuje plik CSV z obs≈ÇugƒÖ b≈Çƒôd√≥w.
        
        Args:
            file_path (Path): ≈öcie≈ºka do pliku CSV
            
        Returns:
            Optional[pd.DataFrame]: DataFrame z danymi lub None w przypadku b≈Çƒôdu
        """
        try:
            if not file_path.exists():
                logger.debug(f"Plik nie istnieje: {file_path}")
                return None
            
            # Wczytaj CSV z obs≈ÇugƒÖ r√≥≈ºnych kodowa≈Ñ
            df = pd.read_csv(file_path, encoding='utf-8')
            
            # Sprawd≈∫ czy DataFrame nie jest pusty
            if df.empty:
                logger.warning(f"Plik CSV jest pusty: {file_path}")
                return None
            
            # Sprawd≈∫ wymagane kolumny - dostosuj do rzeczywistych plik√≥w CSV
            # Obs≈Çuguj zar√≥wno stary format (video_id, title, views_today) jak i nowy (Video_ID, Title, View_Count)
            required_columns_old = ['video_id', 'title', 'views_today']
            required_columns_new = ['Video_ID', 'Title', 'View_Count']
            
            # Sprawd≈∫ czy mamy stary format
            missing_columns_old = [col for col in required_columns_old if col not in df.columns]
            # Sprawd≈∫ czy mamy nowy format
            missing_columns_new = [col for col in required_columns_new if col not in df.columns]
            
            if missing_columns_old and missing_columns_new:
                logger.error(f"Brak wymaganych kolumn w {file_path}. Stary format: {missing_columns_old}, Nowy format: {missing_columns_new}")
                return None
            
            logger.debug(f"Pomy≈õlnie wczytano {len(df)} rekord√≥w z {file_path}")
            return df
            
        except FileNotFoundError:
            logger.debug(f"Plik nie znaleziony: {file_path}")
            return None
        except pd.errors.EmptyDataError:
            logger.warning(f"Plik CSV jest pusty: {file_path}")
            return None
        except pd.errors.ParserError as e:
            logger.error(f"B≈ÇƒÖd parsowania CSV {file_path}: {e}")
            return None
        except UnicodeDecodeError as e:
            logger.error(f"B≈ÇƒÖd kodowania UTF-8 w {file_path}: {e}")
            return None
        except Exception as e:
            logger.error(f"Nieoczekiwany b≈ÇƒÖd podczas wczytywania {file_path}: {e}")
            return None
    
    def _process_trend_data(self, today_df: pd.DataFrame, yesterday_df: Optional[pd.DataFrame]) -> List[Dict[str, Any]]:
        """
        Przetwarza dane trend√≥w i oblicza przyrosty.
        
        Args:
            today_df (pd.DataFrame): Dzisiejsze dane
            yesterday_df (Optional[pd.DataFrame]): Wczorajsze dane
            
        Returns:
            List[Dict[str, Any]]: Lista przetworzonych rekord√≥w
        """
        try:
            # Skopiuj dzisiejsze dane
            result_df = today_df.copy()
            
            # Okre≈õl format pliku CSV
            is_new_format = 'Video_ID' in today_df.columns and 'Title' in today_df.columns and 'View_Count' in today_df.columns
            is_old_format = 'video_id' in today_df.columns and 'title' in today_df.columns and 'views_today' in today_df.columns
            
            if not (is_new_format or is_old_format):
                logger.error("Nieznany format pliku CSV")
                return []
            
            # Mapuj kolumny na standardowe nazwy
            if is_new_format:
                # Nowy format: Video_ID, Title, View_Count, Duration
                video_id_col = 'Video_ID'
                title_col = 'Title'
                view_count_col = 'View_Count'
                duration_col = 'Duration'
                channel_col = 'Channel_Name'
            else:
                # Stary format: video_id, title, views_today, duration_seconds
                video_id_col = 'video_id'
                title_col = 'title'
                view_count_col = 'views_today'
                duration_col = 'duration_seconds'
                channel_col = 'channel'
            
            # Dodaj kolumnƒô video_type na podstawie Duration
            def safe_parse_duration(duration_val):
                """Bezpiecznie parsuje Duration i zwraca video_type"""
                try:
                    if pd.isna(duration_val):
                        return "Longform"
                    
                    if is_new_format:
                        # Nowy format: Duration w formacie ISO 8601 (PT1H2M3S)
                        duration_str = str(duration_val)
                        if not duration_str.startswith('PT'):
                            return "Longform"
                        
                        # Parsuj format PT1H2M3S
                        hours = 0
                        minutes = 0
                        seconds = 0
                        
                        if 'H' in duration_str:
                            hours = int(duration_str.split('H')[0].split('T')[1])
                        if 'M' in duration_str:
                            minutes = int(duration_str.split('M')[0].split('T')[-1])
                        if 'S' in duration_str:
                            seconds = int(duration_str.split('S')[0].split('T')[-1])
                        
                        total_seconds = hours * 3600 + minutes * 60 + seconds
                        # Filmy do 3 minut (180 sekund) to shorts, powy≈ºej to long-form
                        return "Shorts" if total_seconds <= 180 else "Longform"
                    else:
                        # Stary format: duration_seconds jako liczba
                        duration_seconds = int(duration_val)
                        # Filmy do 3 minut (180 sekund) to shorts, powy≈ºej to long-form
                        return "Shorts" if duration_seconds <= 180 else "Longform"
                    
                except (ValueError, TypeError):
                    # W przypadku b≈Çƒôdu parsowania, domy≈õlnie Longform
                    return "Longform"
            
            result_df['video_type'] = result_df[duration_col].apply(safe_parse_duration)
            
            # Inicjalizuj kolumnƒô delta
            result_df['delta'] = 0
            
            # Je≈õli mamy wczorajsze dane, oblicz przyrosty
            if yesterday_df is not None and not yesterday_df.empty:
                # Mapuj wczorajsze wy≈õwietlenia po video_id
                yesterday_views = yesterday_df.set_index(video_id_col)[view_count_col].to_dict()
                
                # Oblicz delta
                result_df['delta'] = result_df.apply(
                    lambda row: row[view_count_col] - yesterday_views.get(row[video_id_col], 0), 
                    axis=1
                )
            
            # Dodaj kolumnƒô thumbnail_url (YouTube thumbnail)
            result_df['thumbnail_url'] = result_df[video_id_col].apply(
                lambda x: f"https://img.youtube.com/vi/{x}/mqdefault.jpg" if pd.notna(x) else ""
            )
            
            # Sortuj malejƒÖco wed≈Çug delta
            result_df = result_df.sort_values('delta', ascending=False)
            
            # Zwr√≥ƒá wszystkie wyniki (nie tylko top 50)
            top_results = result_df
            
            # Konwertuj do listy s≈Çownik√≥w
            result_list = []
            for _, row in top_results.iterrows():
                result_list.append({
                    'title': str(row.get(title_col, '')),
                    'views': int(row.get(view_count_col, 0)),
                    'delta': int(row.get('delta', 0)),
                    'video_type': str(row.get('video_type', 'Longform')),
                    'thumbnail_url': str(row.get('thumbnail_url', '')),
                    'video_id': str(row.get(video_id_col, '')),
                    'channel': str(row.get(channel_col, '')),
                    'duration': str(row.get(duration_col, ''))
                })
            
            return result_list
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas przetwarzania danych trend√≥w: {e}")
            return []
    
    def get_available_dates(self, category: str) -> List[str]:
        """
        Zwraca listƒô dostƒôpnych dat dla danej kategorii.
        
        Args:
            category (str): Nazwa kategorii
            
        Returns:
            List[str]: Lista dat w formacie YYYY-MM-DD
        """
        try:
            if not self.base_path.exists():
                logger.warning(f"Katalog raport√≥w nie istnieje: {self.base_path}")
                return []
            
            # Wzorzec pliku
            pattern = f"report_{category.upper()}_*.csv"
            
            # Znajd≈∫ pliki
            csv_files = list(self.base_path.glob(pattern))
            
            # WyciƒÖgnij daty z nazw plik√≥w
            dates = []
            for file_path in csv_files:
                try:
                    # Format: report_PODCAST_2025-08-13.csv
                    filename = file_path.stem  # bez rozszerzenia
                    date_part = filename.split('_')[-1]
                    
                    # Sprawd≈∫ czy to poprawna data
                    date.fromisoformat(date_part)
                    dates.append(date_part)
                except (ValueError, IndexError):
                    continue
            
            # Sortuj daty malejƒÖco (najnowsze pierwsze)
            dates.sort(reverse=True)
            
            logger.info(f"Znaleziono {len(dates)} dostƒôpnych dat dla kategorii {category}")
            return dates
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas pobierania dostƒôpnych dat dla {category}: {e}")
            return []


# Funkcja pomocnicza dla ≈Çatwiejszego dostƒôpu
def get_trend_data(category: str, report_date: date) -> List[Dict[str, Any]]:
    """
    Funkcja pomocnicza do pobierania danych trend√≥w.
    
    Args:
        category (str): Nazwa kategorii
        report_date (date): Data raportu
        
    Returns:
        List[Dict[str, Any]]: Lista danych trend√≥w
    """
    processor = CSVProcessor()
    return processor.get_trend_data(category, report_date)
