"""
Serwis do przetwarzania danych z raportÃ³w CSV dla moduÅ‚u trend.
Zapewnia niezawodne wczytywanie i analizÄ™ danych z plikÃ³w CSV.
"""

try:
    import pandas as pd
    import logging
    from datetime import date, timedelta
    from typing import List, Dict, Any, Optional
    from pathlib import Path
    
    print("âœ… Wszystkie importy w csv_processor udane")
except ImportError as e:
    print(f"âŒ BÅ‚Ä…d importu w csv_processor: {e}")
    import traceback
    traceback.print_exc()
    raise

logger = logging.getLogger(__name__)

class CSVProcessor:
    """Klasa do przetwarzania plikÃ³w CSV z raportami trendÃ³w"""
    
    def __init__(self):
        # UÅ¼yj Railway Volume Path zamiast lokalnego katalogu
        from app.config.settings import settings
        self.base_path = settings.reports_path
    
    def get_trend_data(self, category: str, report_date: date) -> List[Dict[str, Any]]:
        """
        Pobiera dane trendÃ³w dla danej kategorii i daty.
        
        Args:
            category (str): Nazwa kategorii (np. "PODCAST")
            report_date (date): Data raportu (ignorowana - uÅ¼ywa najnowszego dostÄ™pnego pliku)
            
        Returns:
            List[Dict[str, Any]]: Lista top 50 wynikÃ³w z danymi trendÃ³w
        """
        try:
            # ZnajdÅº najnowszy dostÄ™pny plik CSV dla danej kategorii
            pattern = f"report_{category.upper()}_*.csv"
            csv_files = list(self.base_path.glob(pattern))
            
            if not csv_files:
                print(f"âŒ CSV Processor: Nie znaleziono plikÃ³w CSV dla kategorii {category}")
                logger.warning(f"Nie znaleziono plikÃ³w CSV dla kategorii {category}")
                return []
            
            # WeÅº najnowszy plik (sortuj po nazwie)
            latest_file = sorted(csv_files)[-1]
            print(f"ðŸ” CSV Processor: UÅ¼ywam najnowszego pliku: {latest_file}")
            
            # Wczytaj najnowszy raport
            latest_df = self._load_csv_safely(latest_file)
            if latest_df is None or latest_df.empty:
                print(f"âŒ CSV Processor: Nie moÅ¼na wczytaÄ‡ raportu: {latest_file}")
                logger.warning(f"Nie moÅ¼na wczytaÄ‡ raportu: {latest_file}")
                return []
            
            # ZnajdÅº poprzedni plik (dla obliczenia delta)
            if len(csv_files) > 1:
                previous_file = sorted(csv_files)[-2]
                print(f"ðŸ” CSV Processor: UÅ¼ywam poprzedniego pliku: {previous_file}")
                previous_df = self._load_csv_safely(previous_file)
            else:
                previous_df = None
            
            # Przygotuj dane
            print(f"ðŸ“Š Przetwarzanie danych: {len(latest_df)} filmÃ³w w najnowszym raporcie")
            result_data = self._process_trend_data(latest_df, previous_df)
            
            print(f"âœ… CSV Processor: PomyÅ›lnie przetworzono {len(result_data)} rekordÃ³w dla kategorii {category}")
            print(f"ðŸ“ˆ Statystyki: {len(latest_df)} â†’ {len(result_data)} filmÃ³w")
            logger.info(f"PomyÅ›lnie przetworzono {len(result_data)} rekordÃ³w dla kategorii {category}")
            return result_data
            
        except Exception as e:
            print(f"âŒ CSV Processor: BÅ‚Ä…d: {e}")
            logger.error(f"BÅ‚Ä…d podczas przetwarzania danych trendÃ³w dla {category} {report_date}: {e}")
            return []
    
    def _load_csv_safely(self, file_path: Path) -> Optional[pd.DataFrame]:
        """
        Bezpiecznie wczytuje plik CSV z obsÅ‚ugÄ… bÅ‚Ä™dÃ³w.
        
        Args:
            file_path (Path): ÅšcieÅ¼ka do pliku CSV
            
        Returns:
            Optional[pd.DataFrame]: DataFrame z danymi lub None w przypadku bÅ‚Ä™du
        """
        try:
            if not file_path.exists():
                logger.debug(f"Plik nie istnieje: {file_path}")
                return None
            
            # Wczytaj CSV z obsÅ‚ugÄ… rÃ³Å¼nych kodowaÅ„
            df = pd.read_csv(file_path, encoding='utf-8')
            
            # SprawdÅº czy DataFrame nie jest pusty
            if df.empty:
                logger.warning(f"Plik CSV jest pusty: {file_path}")
                return None
            
            # SprawdÅº wymagane kolumny - dostosuj do rzeczywistych plikÃ³w CSV
            # ObsÅ‚uguj zarÃ³wno stary format (video_id, title, views_today) jak i nowy (Video_ID, Title, View_Count)
            required_columns_old = ['video_id', 'title', 'views_today']
            required_columns_new = ['Video_ID', 'Title', 'View_Count']
            
            # SprawdÅº czy mamy stary format
            missing_columns_old = [col for col in required_columns_old if col not in df.columns]
            # SprawdÅº czy mamy nowy format
            missing_columns_new = [col for col in required_columns_new if col not in df.columns]
            
            if missing_columns_old and missing_columns_new:
                logger.error(f"Brak wymaganych kolumn w {file_path}. Stary format: {missing_columns_old}, Nowy format: {missing_columns_new}")
                return None
            
            logger.debug(f"PomyÅ›lnie wczytano {len(df)} rekordÃ³w z {file_path}")
            return df
            
        except FileNotFoundError:
            logger.debug(f"Plik nie znaleziony: {file_path}")
            return None
        except pd.errors.EmptyDataError:
            logger.warning(f"Plik CSV jest pusty: {file_path}")
            return None
        except pd.errors.ParserError as e:
            logger.error(f"BÅ‚Ä…d parsowania CSV {file_path}: {e}")
            return None
        except UnicodeDecodeError as e:
            logger.error(f"BÅ‚Ä…d kodowania UTF-8 w {file_path}: {e}")
            return None
        except Exception as e:
            logger.error(f"Nieoczekiwany bÅ‚Ä…d podczas wczytywania {file_path}: {e}")
            return None
    
    def _process_trend_data(self, today_df: pd.DataFrame, yesterday_df: Optional[pd.DataFrame]) -> List[Dict[str, Any]]:
        """
        Przetwarza dane trendÃ³w i oblicza przyrosty.
        
        Args:
            today_df (pd.DataFrame): Dzisiejsze dane
            yesterday_df (Optional[pd.DataFrame]): Wczorajsze dane
            
        Returns:
            List[Dict[str, Any]]: Lista przetworzonych rekordÃ³w
        """
        try:
            # Skopiuj dzisiejsze dane
            result_df = today_df.copy()
            
            # OkreÅ›l format pliku CSV
            is_new_format = 'Video_ID' in today_df.columns and 'Title' in today_df.columns and 'View_Count' in today_df.columns
            is_old_format = 'video_id' in today_df.columns and 'title' in today_df.columns and 'views_today' in today_df.columns
            
            if not (is_new_format or is_old_format):
                logger.error("Nieznany format pliku CSV")
                return []
            
            # Mapuj kolumny na standardowe nazwy
            if is_new_format:
                # Nowy format: Video_ID, Title, View_Count, Duration
                video_id_col = 'Video_ID'
                title_col = 'Title'
                view_count_col = 'View_Count'
                duration_col = 'Duration'
                channel_col = 'Channel_Name'
            else:
                # Stary format: video_id, title, views_today, duration_seconds
                video_id_col = 'video_id'
                title_col = 'title'
                view_count_col = 'views_today'
                duration_col = 'duration_seconds'
                channel_col = 'channel'
            
            # Dodaj kolumnÄ™ video_type na podstawie Duration
            def safe_parse_duration(duration_val):
                """Bezpiecznie parsuje Duration i zwraca video_type"""
                try:
                    if pd.isna(duration_val):
                        return "Longform"
                    
                    if is_new_format:
                        # Nowy format: Duration w formacie ISO 8601 (PT1H2M3S)
                        duration_str = str(duration_val)
                        if not duration_str.startswith('PT'):
                            return "Longform"
                        
                        # Parsuj format PT1H2M3S
                        hours = 0
                        minutes = 0
                        seconds = 0
                        
                        # Parsuj godziny (H)
                        if 'H' in duration_str:
                            hours_part = duration_str.split('H')[0]
                            hours = int(hours_part.split('T')[1])
                        
                        # Parsuj minuty (M) - uwaga na kolejnoÅ›Ä‡!
                        if 'M' in duration_str:
                            # ZnajdÅº czÄ™Å›Ä‡ z minutami (po H, przed S)
                            if 'H' in duration_str:
                                # Format: PT1H2M3S
                                minutes_part = duration_str.split('H')[1].split('M')[0]
                            else:
                                # Format: PT2M3S
                                minutes_part = duration_str.split('M')[0].split('T')[1]
                            minutes = int(minutes_part)
                        
                        # Parsuj sekundy (S)
                        if 'S' in duration_str:
                            # ZnajdÅº czÄ™Å›Ä‡ z sekundami (po M lub po T)
                            if 'M' in duration_str:
                                # Format: PT1H2M3S lub PT2M3S
                                seconds_part = duration_str.split('M')[1].split('S')[0]
                            else:
                                # Format: PT3S
                                seconds_part = duration_str.split('T')[1].split('S')[0]
                            seconds = int(seconds_part)
                        
                        total_seconds = hours * 3600 + minutes * 60 + seconds
                        # Filmy do 10 minut (600 sekund) to shorts, powyÅ¼ej to long-form
                        return "Shorts" if total_seconds <= 600 else "Longform"
                    else:
                        # Stary format: duration_seconds jako liczba
                        duration_seconds = int(duration_val)
                        # Filmy do 10 minut (600 sekund) to shorts, powyÅ¼ej to long-form
                        return "Shorts" if duration_seconds <= 600 else "Longform"
                    
                except (ValueError, TypeError):
                    # W przypadku bÅ‚Ä™du parsowania, domyÅ›lnie Longform
                    return "Longform"
            
            # Debugowanie parsowania Duration
            print(f"ðŸ” Parsowanie Duration dla {len(result_df)} filmÃ³w...")
            
            # SprawdÅº problematyczne Duration
            problematic_durations = result_df[result_df[duration_col].isin(['P0D', '', 'nan', 'None'])]
            if not problematic_durations.empty:
                print(f"âš ï¸ Znaleziono problematyczne Duration:")
                for _, row in problematic_durations.iterrows():
                    print(f"   - {row.get(title_col, '')[:50]}... | Duration: '{row.get(duration_col, '')}' | Views: {row.get(view_count_col, 0)}")
            
            result_df['video_type'] = result_df[duration_col].apply(safe_parse_duration)
            
            # Inicjalizuj kolumnÄ™ delta
            result_df['delta'] = 0
            
            # JeÅ›li mamy wczorajsze dane, oblicz przyrosty
            if yesterday_df is not None and not yesterday_df.empty:
                # Mapuj wczorajsze wyÅ›wietlenia po video_id
                yesterday_views = yesterday_df.set_index(video_id_col)[view_count_col].to_dict()
                
                # Oblicz delta
                result_df['delta'] = result_df.apply(
                    lambda row: row[view_count_col] - yesterday_views.get(row[video_id_col], 0), 
                    axis=1
                )
            
            # Dodaj kolumnÄ™ thumbnail_url (YouTube thumbnail)
            result_df['thumbnail_url'] = result_df[video_id_col].apply(
                lambda x: f"https://img.youtube.com/vi/{x}/mqdefault.jpg" if pd.notna(x) else ""
            )
            
            # Sortuj malejÄ…co wedÅ‚ug delta
            result_df = result_df.sort_values('delta', ascending=False)
            
            # ZwrÃ³Ä‡ wszystkie wyniki (nie tylko top 50)
            top_results = result_df
            
            # Konwertuj do listy sÅ‚ownikÃ³w
            result_list = []
            for _, row in top_results.iterrows():
                # PomiÅ„ zaplanowane transmisje live (0 wyÅ›wietleÅ„, niepoprawny Duration)
                views = int(row.get(view_count_col, 0))
                duration = str(row.get(duration_col, ''))
                
                # Filtruj filmy z 0 wyÅ›wietleniami lub niepoprawnym Duration
                if views == 0 or duration == 'P0D' or duration == '':
                    print(f"âš ï¸ Pomijam film: {row.get(title_col, '')[:50]}... (views: {views}, duration: {duration})")
                    continue
                
                result_list.append({
                    'title': str(row.get(title_col, '')),
                    'views': views,
                    'delta': int(row.get('delta', 0)),
                    'video_type': str(row.get('video_type', 'Longform')),
                    'thumbnail_url': str(row.get('thumbnail_url', '')),
                    'video_id': str(row.get(video_id_col, '')),
                    'channel': str(row.get(channel_col, '')),
                    'duration': duration
                })
            
            print(f"âœ… Po filtrowaniu: {len(result_list)} filmÃ³w (pominiÄ™to zaplanowane transmisje live)")
            return result_list
            
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas przetwarzania danych trendÃ³w: {e}")
            return []
    
    def get_available_dates(self, category: str) -> List[str]:
        """
        Zwraca listÄ™ dostÄ™pnych dat dla danej kategorii.
        
        Args:
            category (str): Nazwa kategorii
            
        Returns:
            List[str]: Lista dat w formacie YYYY-MM-DD
        """
        try:
            if not self.base_path.exists():
                logger.warning(f"Katalog raportÃ³w nie istnieje: {self.base_path}")
                return []
            
            # Wzorzec pliku
            pattern = f"report_{category.upper()}_*.csv"
            
            # ZnajdÅº pliki
            csv_files = list(self.base_path.glob(pattern))
            
            # WyciÄ…gnij daty z nazw plikÃ³w
            dates = []
            for file_path in csv_files:
                try:
                    # Format: report_PODCAST_2025-08-13.csv
                    filename = file_path.stem  # bez rozszerzenia
                    date_part = filename.split('_')[-1]
                    
                    # SprawdÅº czy to poprawna data
                    date.fromisoformat(date_part)
                    dates.append(date_part)
                except (ValueError, IndexError):
                    continue
            
            # Sortuj daty malejÄ…co (najnowsze pierwsze)
            dates.sort(reverse=True)
            
            logger.info(f"Znaleziono {len(dates)} dostÄ™pnych dat dla kategorii {category}")
            return dates
            
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas pobierania dostÄ™pnych dat dla {category}: {e}")
            return []


# Funkcja pomocnicza dla Å‚atwiejszego dostÄ™pu
def get_trend_data(category: str, report_date: date) -> List[Dict[str, Any]]:
    """
    Funkcja pomocnicza do pobierania danych trendÃ³w.
    
    Args:
        category (str): Nazwa kategorii
        report_date (date): Data raportu
        
    Returns:
        List[Dict[str, Any]]: Lista danych trendÃ³w
    """
    processor = CSVProcessor()
    return processor.get_trend_data(category, report_date)
